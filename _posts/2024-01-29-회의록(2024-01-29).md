---
layout: single
title:  "🧑‍🤝‍🧑 회의록(2024-01-29)"
excerpt: "오프라인 아이디어 회의 진행"
categories: Meeting
# tag: [python, blog, food]
toc: true
toc_sticky: true
typora-root-url: ../
auto_profile: false
# sidebar:
#    nav: "docs"
# search: false
---

<br/>

**[활동 기록]**  
활동 기간 : 2024-01-29 (월), 10:00 ~ 17:00  
활동 장소 : 인천대학교 송도캠퍼스 이룸관  
참여자 : [정동교], 고명훈, 김성웅(온라인), 김우찬  
기록자 : [정동교] 
{: .notice--danger .text-center}

<br/>

# 1. 아이디어 회의

## 회의 개요

이전 회의를 통해서 데이터를 통해 아이디어를 찾아보자고 결론을 내렸다. 따라서 오늘은 **다양한 데이터를 탐색해 보면서 메인 아이디어가 반려될 경우를 대비하여 서브 아이디어**를 정해보는 시간을 갖는다.

지금까지 수 차례의 회의를 거치며 생각해 본 결과, 학부생 수준에서 AI를 활용하여 작품을 만드는 것에는 아무래도 한계가 있는 것 같다고 판단했다. 그 이유는 **모델 학습을 시키기 위한 자원**(*H/W Resource 및 학습에 소모되는 돈*)도 부족하며, 결론적으로 **모델을 학습시킬 데이터를 찾아내는 것**이 굉장히 어렵기 때문이다. 따라서 많은 고민을 해보고 여러 자료를 탐색해보지 않으면 좋은 아이디어를 얻기 어려울 것이며, 마찬가지로 좋은 작품도 만들지 못할 것이다.

우리 팀원들은 이번 캡스턴디자인 활동을 통해서 많은 것을 배우고 의미 있는 시간을 보내고자 한다. 따라서 흔하지 않고 창의적인 아이디어를 시도해 보고자 하며, 다소 대중적이고 일반적인 모델을 사용하기 보다는 새로운 모델을 공부해보고 직접 데이터도 학습시켜 보는 것을 목표한다.

하지만 우리 팀이 아무리 노력하더라도 항상 좋은 결과를 얻을 수는 없을 것이다. 만약 아이디어 탐색 단계에서 만족스러운 결과를 얻지 못한다면 **OpenCV**, **YOLO** 등의 대중적인 모델을 활용해 보도록 하자.

이번 시간의 목표는 특히 '**메인 아이디어가 반려될 경우를 대비하여 서브 아이디어를 정해보는 것**' 이기 때문에, OpenCV, YOLO 등을 활용하여 구현할 수 있는 아이디어를 위주로 생각해 보았다.

<br>

## 데이터 기반 접근을 통한 아이디어 탐색

이전에 기록하였던 것처럼, 인터넷에서 얻을 수 있는 다양한 데이터를 탐색해보며 아이디어를 얻어 보고자 한다. 데이터는 Google의 Dataset Search 기능을 활용하여 다양한 Keyword를 검색해보며 얻어내었다.

[Google Dataset Search](https://datasetsearch.research.google.com/)
{: .text-center}

<br>

- **안전모/안전화/안전 장갑/야광 조끼 등, 안전 장비에 대한 Labeling 이미지 데이터 셋**

  ![image-20240130165331819](/images/2024-01-29-회의록(2024-01-29)/image-20240130165331819.png){:. img-with-large}

<br>

- **현장 안전모 미착용 알림 시스템 개발을 위한 안전모 객체 이미지 학습용 데이터**

![image-20240130165510882](/images/2024-01-29-회의록(2024-01-29)/image-20240130165510882.png){: .img-width-large}

<br>

- **콘크리트에 손상이 발생한 부분을 Labeling한 데이터 셋**

![image-20240130173831738](/images/2024-01-29-회의록(2024-01-29)/image-20240130173831738.png){: .img-width-large}

다양한 데이터 셋을 찾아보았으나, 생각보다 데이터와 좋은 아이디어를 연결하기는 쉽지 않았다. 그나마 사용해 볼 만한 것들은 위에 기록해 두었다. 그 중에서도 **공사장 안전 장비 데이터**는 안전 상태 모니터링 등과 같은 아이디어로 연결하여 사용할 수 있을 것 같아 기록해 두었다.

추가적으로, 다음 아이디어와 연결하면 더 좋은 아이디어가 될 수 있을 것이다.

- [**건설 현장 위험 상태 판단 데이터**](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=71407)



이 데이터들을 통해 **노동자의 복장 상태를 점검하는 Gate**를 만들고, 이후에 **실시간으로 건강 상태 등을 관리자가 모니터링 할 수 있는 시스템을 제안**한다. 또는 **건설 현장 위험 상태 판단 데이터를 결합**하여 **현장의 위험물을 선제적으로 예측하여 경고**해 주는 **스마트 헬멧** 등을 제작할 수도 있을 것이다.

건설 현장 안전 상태 모니터링과 관련한 아이디어는 중대재해법을 바탕으로 **작성할만한 근거가 충분**하므로, 문제 해결의 필요성이나 가치 등에서는 충분히 내용을 제시할 수 있을 것이다. 그런데, **<u>생각보다 건설 현장 모니터링과 관련하여 이미 이루어진 시도가 많다.</u>** 따라서 **평범한 내용으로는 절대 통과하지 못할 것이기 때문에 추가적인 아이디어를 결합하려는 시도**를 해 보아야 한다.

<u>다만 이것은 어디까지나 서브 아이디어이기 때문에, 우선 Eye-Tracking 구현을 시도하자.</u>

<br>

# 2. 기존 아이디어에 대한 추가 활용 방안 탐색

다양한 데이터 셋을 찾아보며, Eye-Tracking에도 적용할만한 데이터 셋을 찾게 되었다. 이 데이터 셋을 기록하고, 본 아이디어에 대해서도 추가 아이디어를 생각해보자.

## 데이터셋

- **블라인드 이미지 데이터 셋 및 집안 사물 이미지 데이터 셋**  
  => 다양한 객체 인식에 사용할 수 있을 것으로 보임.
- **동공 감지 데이터 셋(적외선 및 각종 데이터)**  
  => 단, 시선에 관하여 Labeling이 되어 있지 않기 때문에 추적 자체는 불가능함.

<br>

## 아이디어 활용 방안

- **가정용이 아닌 점원 및 직원 전용 제품으로 확장**

스마트 홈이 아닌 다른 분야에도 스마트 글래스를 적용할 수 있을지 고민해 보았다. 스마트 홈에 적용하지 않는다면 매장 등에서 직원이 빠른 일처리를 위해 사용할 수도 있을 것이라고 생각이 드는데, 생각보다 좋은 아이디어 같지는 않아서 넘어갔다.

<br>

- **Eye-Tracking 제품에 터치 기능 추가 활용**

Eye-Tracking을 스마트 홈에 적용하려는 시도 자체는 아직까지는 없었지만, 기존에도 Eye-Tracking 글래스 제품들이 존재하긴 했다. 이런 제품들과 차별성이 필요하기 때문에, 글래스에 터치 인식할 수 있는 패드를 만들어 인터랙션이 가능하도록 만들어 보고자 한다.

[우정 하이텍의 투명 터치 필름](https://www.devicemart.co.kr/goods/view?no=10916844)
{: .text-center}

이 터치 센서를 이용하면 복잡한 모듈 없이도 간단하게 터치를 구현할 수 있다.

<br>

- **바코드 혹은 QR 코드 인식을 활용한 기능**

바코드를 인식하여 결제를 하거나, QR을 인식하여 특정한 기능을 수행하는 등의 기능까지 확장 가능

<br>

- **외관(디자인)**

글래스를 최대한 경량화하고 간단하게 만들기 위하여 안경테의 속을 비게 만들어 케이블을 통과시킬 수 있도록 만들고, 이를 센서와 연결하여 보드와 통신할 수 있도록 한다. 

그리고 투명 터치 필름을 붙일 수 있도록 안경테에 1.5cm x 1.5cm 크기 정도의 정사각형 모양의 공간을 확보하도록 한다.

카메라는 내부의 눈을 촬영할 수 있도록 안 쪽에 두 개를 장착, 외부를 촬영하기 위해 코 받침대의 정 반대편에 하나를 부착하도록 한다. => 최대한 소형 카메라로 사용

<br>

- **Gesture 활용**

Gesture 자체로는 한계가 있었지만, 스마트 글래스와 결합하면 유용한 기능을 만들어 낼 수 있다. 다양한 방식으로 고민해보자.

<br>

## 아이디어의 가치

이후에 보고서를 작성할 때는 다음 가치를 중심으로 작성해 보도록 한다. 단, 장애인 및 노약자와 관련한 내용은 반드시 근거 자료가 필요할 것이기 때문에 충분한 사전 조사가 진행되어야 한다.



- 장애인의 제품 이용 제약 상황에서 불편 개선
- 노약자의 거동 불편으로 인한 제품 사용 불편함 개선
- IoT 기술 발전에 따른 편의 기술 연계



또한 기존에 본 아이디어와 비슷한 시도는 있었으나, 우리는 전반적인 Eye-Tracking 기반의 아키텍처 자체를 제시하는 느낌으로 방향성을 잡으면 어느 정도 차별성을 확보할 수 있을 것이라고 생각함.

현재까지는 시선 추적을 중심으로 한 스마트 홈 아키텍처를 구현하려는 시도는 없었던 것으로 보인다. (*관련 논문은 있기 때문에 참고하거나 인용할 수 있을 것*) 이것은 아직 **스마트 홈 자체가 완벽히 대중화되지 않았으며**, 따라서 스마트 interaction이 가능한 제품이 많지 않은 만큼 사람들이 기본적인 상호작용을 넘어서는 **시선 추적 제품에 대한 필요성을 느끼지 못할 수도 있기 때문일 것**으로 생각한다. 그러나 스마트 홈이 하나의 트렌드로서 자리매김하고 있는 만큼, 앞으로는 많은 사람들이 스마트 홈 서비스를 이용하게 될 것이며, 이에 따라 시선 추적 기술을 사용한 interaction이 유용하게 사용될 것이라고 생각한다.

<br>

# 3. 추가 논의

## 추후 일정

- 2024-02-01 (목) 10:00에 오프라인 회의 진행 (인천대학교 송도 캠퍼스 이룸관)

<br>

## 과제

- 시선 추적 기술의 구현 가능성에 대해서 각자 조사를 진행
- 참고 링크

[유튜브 영상](https://www.youtube.com/watch?v=rsepKaSXCls)
{: .text-center}

[깃허브](https://github.com/SeonminKim1/PJ-Eyetracking_SmartGlass/blob/master/SourceCode/main.cpp)
{: .text-center}

- GazeMapping 기술에 대해서 찾아보기

<br>









