---
layout: single
title:  "🧑‍🤝‍🧑 회의록(2024-01-22)"
excerpt: "오프라인 아이디어 회의 진행"
categories: Meeting
# tag: [python, blog, food]
toc: true
toc_sticky: true
typora-root-url: ../
auto_profile: false
# sidebar:
#    nav: "docs"
# search: false
---

<br/>

**[활동 기록]**  
활동 기간 : 2024-01-22 (월), 09:00 ~ 17:00  
활동 장소 : 인천대학교 송도캠퍼스 이룸관  
참여자 : [정동교], 고명훈, 김성웅(온라인), 김우찬  
기록자 : [정동교] 
{: .notice--danger .text-center}

<br/>

# 1. 아이디어 회의 진행

## 활동 진행과정 정리

2024-01-19 (금)에 온라인 회의를 진행하였는데, 이때 우리 팀은 다음과 같은 관점에서 아이디어를 도출해 보기로 하였고, 각자 준비하여 발표를 진행하였다.

- **활용 가능한 AI 모델 중심**
- **2024-01-15 (월)에 나왔던 핵심 아이디어를 바탕으로 구체화**
- **각자 특정 Domain을 중심으로 문제 인식**

그러나 **AI 모델을 우선적으로 찾는 것**은 아이디어가 정해져 있지 않아 찾아내기도 힘들 뿐더러, 활용 범위를 파악하기도 어렵다는 점에서 한계가 존재했다.

또한 **이전에 나왔던 핵심 아이디어를 바탕으로 구체화**를 시도하였으나 팀원들 모두가 만족할 만큼 좋은 아이디어는 나오지 않았다.

마지막으로 각자 **특정 Domain을 중심으로 문제 인식을 통해 새로운 아이디어를 도출**하고자 하였으나, 지금까지 알지 못하던 분야에 대해서 전문적인 지식을 가져야 하는 만큼 어려운 작업이기 때문에 좋은 아이디어를 얻지는 못했다.

<br>

따라서 오늘은 오프라인 회의를 진행하며 **이전까지 시도하지 않았던 새로운 관점과 방식을 통해서 아이디어를 도출**하고자 한다.

- 뉴스기사/구글링을 통해 다양한 이슈를 보며 실시간으로 자유롭게 토의 주제를 던지고, 이를 바탕으로 꼬리에 꼬리를 물면서 의견을 제시함으로써 새로운 인사이트 및 아이디어를 도출한다.
- 인터넷 상에 존재하는 빅데이터를 살펴보며 인사이트 및 아이디어를 도출한다. (*하단에 링크 첨부*)

<br>

[머신러닝 데이터셋(dataset) 사이트 40가지 모음](https://kr.appen.com/blog/best-datasets/)

[AI-Hub](https://aihub.or.kr/)

[보건의료빅데이터개방시스템](https://opendata.hira.or.kr/home.do)

[Find Open Datasets and Machine Learning Projects](https://www.kaggle.com/datasets)

[Dataset Search](https://datasetsearch.research.google.com/?ref=blog-ko.superb-ai.com)

[컴퓨터 비전 데이터셋 - 공공 데이터셋 살펴보기](https://blog-ko.superb-ai.com/exploring-computer-vision-datasets/)

<br>

약 8시간 동안 아이디어 회의를 진행하며 많은 의견을 주고 받았다. 그 중에서도 이전에 우리가 설정한 평가 기준에 따라 내부적으로 어느 정도 좋은 평가를 받은 핵심 아이디어 위주로 기록하였다.  
(*평가 기준 하단 첨부*. ***<u>분량 조절을 위해 모든 아이디어를 기록하지는 않았음.</u>***)

<br>

## 평가 기준

- **창의성**
  - 딱 보고 “오~” 할 만한 아이디어인가? (*좋은 작품이라는 감상이 곧바로 드는지*)
  - 기존에 없던 것인가?
- **수익화가능성**
  - 인식한 문제를 실질적으로 해결할 수 있는가?
  - 방법이 효율적인가?
  - 해당 문제에 관심 있는 사람들이 쓸 거 같은가?
- **기술성**
  - AI분야에서 완성도가 높은가?
  - H/W의 완성도는 높은가?
  - 사용자와 상호작용 할 수 있는가? (필수적이지는 않지만, 상호작용이 있으면 좋다고 평가됨.)

<br>

## 아이디어

### 1. Gesture

> 이전 회의에서 핵심 아이디어로 다루었던 Gesture라는 컨셉을 주제로 하는 아이디어이다.

<br>

- **Gesture To Spray**

**Gesture To Spray**는 Samsung Galaxy S24에서 나온 기능인 **Circle to Search** 기능과, **Gesture 기능**을 결합하여 생각해 낸 아이디어이다. **특정한 Gesture를 취할 경우, 해당 Gesture에 연결되는 특수한 기능이 수행**되는 디바이스 혹은 그러한 시스템을 만드는 것이다.

**모니터링 디바이스에서 특정한 영역을 터치, 드래그 할 경우 해당 영역에 뭔가를 분사하는 방식**의 아이디어이다. **농업**, **화재 진압**, **염화칼슘 분사로 눈 녹이기**, **일부 산업군** 등 **사람의 섬세한 모니터링이 필요할 경우** 유용하게 사용될 수 있을 것으로 생각된다.

<br>

하지만 농업의 경우 이미 **자율주행 농사 자동화 트랙터**가 나온 상황에서 효용이 존재할지 의문을 갖게 되었고, **화재 진압**은 실제 시연이 어렵다는 점에서 탈락, 유용한 산업군은 나중에 조사하면 좋은 부분이 나타날 수 있기 때문에 우선 임시로 기록해 두기로 했다.

<br>

### 2. 품질 검사 및 품질 관리

> 이전까지는 특정한 사례 및 사고 등을 기반으로 아이디어를 찾아보고자 했었으나, 계속해서 진행이 막히기 시작했다. 이에 따라 특정한 산업 영역에 입각하여 아이디어를 내보자는 의견이 제시되었고, 그 중에서도 **품질 검사 및 품질 관리**의 관점에서 아이디어를 찾아보고자 했다.
>
> 품질 검사 및 관리는 대부분의 생산 공정에서 이미 굉장히 높은 수준으로, 그리고 전문적으로 수행되고 있다. 따라서 우리가 그 부분을 개선하는 것은 사실상 불가능하다. 이에 따라 우리는 '***사후 검사 및 관리***'에 초점을 맞추기로 하였다.

<br>

- **겨울철 배관 동파 방지를 위한 모니터링 시스템**

겨울철에는 배관이 동파되는 경우가 많다. 2023년 1월에는 하루 동안 인천시에서 신고된 동파 신고만 약 20건이 넘어간다고 한다. 동파가 발생할 경우 많은 가구가 단수될 수 있기 때문에 **겨울철 배관 관리**는 매우 중요한 사항 중 하나이다. 이에 따라 효율적으로 **배관의 동파 가능성을 모니터링**하고 이를 **관리**할 수 있는 시스템을 만드는 것도 좋은 아이디어라고 생각된다. **주기적으로 파이프의 안전성을 자동 검사**하고, **동파 위험이 감지된다면 이에 따라 적절한 조치**를 취하는 방식으로 동작하도록 설계한다.

<br>

**<u>다만 개발 과정에서 어려울 것으로 예상되는 부분이 몇 가지 존재한다.</u>**

1) **동파가 언제 발생하는지 판단할 근거를 알아야 한다.** 단순한 알고리즘으로 판단해도 되지만, 그러면 전문성이 다소 떨어질 수 있기 때문에 관련 공공기관 등에 문의해서 데이터를 수집하거나 정보를 얻어야 할 것이다.

   

2) **테스트 및 시연이 거의 불가능하다.** 이걸 테스트하거나 시연하려면 정말로 배관을 동파시켜야 하는데, 우리가 가진 자원으로는 사실상 구현이 거의 불가능하다.

<br>

- **안경 스크래치(Scratch) 검사기**

대부분의 안경은 사용하다보면 **스크래치**가 생기게 되며, 이는 시력에 큰 악영향을 줄 수 있다. 그러나 대부분의 사람들은 자신의 안경에 스크래치가 발생했는지 잘 모르며, 이게 얼마나 생겼을 때 문제가 돼서 안경을 바꿔야 하는지를 알기도 매우 어렵다.

따라서 Segmentation 혹은 Detection 등을 수행하는 알고리즘을 이용한 Vision 처리를 통해 스크래치를 파악하고, 현재 안경 상태가 시력에 영향을 줄 수 있는지를 판단하는 작업을 수행하도록 만들면 될 것 같다. 

<br>

**<u>그런데 이 아이디어 역시 개발 과정이 어려워 질 것으로 예상되는 부분이 존재한다.</u>**

1) **Labled 데이터가 존재하지 않는다.** 물론 더 찾아보기는 해야겠지만, 현재로서는 안경을 정면에서 찍은 데이터는 거의 없는 것으로 보인다. 이에 따라 **지도학습은 거의 불가능**할 것으로 보이며, 현재 추측으로는 **비지도학습**, 그 중에서도 **Anomaly Detection**과 유사한 알고리즘으로 수행해야 하지 않을까? 하는 생각이 든다.

   

2)  **안경에 얼마나 스크래치가 발생해야 문제가 되는지 알기 힘들다.** 이는 전문적인 요소이기 때문에, 반드시 전문가 인터뷰가 필요할 것으로 생각된다.

   

3)  **딥러닝이 필요하지 않은 부분일 수도 있다.** 딥러닝이 모든 문제를 해결하는 만능 해결사는 아니다. 어쩌면 이 분야도 딥러닝이 해결하지 못하는 분야일 수도 있으며, 해결이 가능하더라도 그것이 딥러닝을 사용하지 않는 방법보다 더 좋은 성능을 낼 것이라는 확신은 불가능하다. 따라서 이 부분에 대해서도 반드시 논의가 필요하다.

[**중요**] 모든 아이디어는 반드시 **타당성**과 근거가 필요하다. 따라서 아이디어가 어느 정도 정해지고 나면 해당 아이디어에 대한 시장 조사 및 환경 분석이 철저하게 이루어져야 할 것이다. Target 설문, 전문가 인터뷰 등이 반드시 필요하다.
{: .notice--success .text-center}

<br>

### 3. Eye-Tracking (❤️)

> **Eye-Tracking** 아이디어는 [AI-hub](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=71421)에서 공개된 데이터 중 **디스플레이를 바라보는 사람의 동공에 대한 Tracking 데이터**를 바탕으로 생각해 낸 아이디어이다. 해당 데이터는 다양한 환경에서 여러 종류(*Smartphone, Monitor, etc*)의 **디스플레이를 바라보는 사람을 촬영한 약 2,500,000장의 사람 정면 이미지**로 구성되어 있으며, 해당 눈이 정확히 어느 지점을 보고 있는지에 대한 수학적 수치로 이루어진 **Labeling 데이터**를 포함하고 있다. 이 데이터를 통해 모델 학습을 진행하면 다양한 작품을 만들 수 있을 것으로 기대된다.

[**주의**] 아래 아이디어들은 사람이 현재 보고있는 지점을 추종할 수 있다는 가정 하에 제시된 아이디어이다.  
위 데이터는 특정 디스플레이를 바라보는 상태에서 수집한 데이터이기 때문에,  
현재 제시된 아이디어들은 실제로 구현되지 못할 가능성이 존재한다.
{: .notice--danger .text-center}

<br>

- **스마트 안전모** 혹은 **운전 경보 시스템**

위의 데이터를 사용하면 사람의 동공을 Tracking 할 수 있기 때문에, 현재 사람이 어느 곳을 보고있는지를 파악할 수 있다. 이를 반대로 생각해서 '**현재 보고있지 않은 곳**'을 찾아내는 곳이 이 아이디어의 핵심이다. 어떤 Domain에 도 적용이 가능하며, 공사현장에서 사용하는 스마트 안전모, 운전 경보 시스템 등은 예시라고 볼 수 있다.

즉, 시야 내의 집중하지 않는 부분에서 나타나는 위험 물체를 감지하여 경고하는 등의 기능을 구현할 수 있다. 다만 운전의 경우 이미 자율주행 분야에서 더 고도화된 연구가 이뤄지고 있기 때문에, **적용 하더라도 가치를 이끌어내기는 힘들 수도 있다.**

<br>

- **디스플레이 중심 안구 인식을 사용한 Non-contact 엘리베이터**

특정 디스플레이를 중심으로 현재 바라보고 있는 지점을 파악하고, 이를 통해 Interaction 할 수 있는 디스플레이를 만드는 아이디어이다. 가장 대표적인 예시로 직접 건드리지 않고도 눈으로 상호작용 할 수 있는 엘리베이터 등을 들 수 있다.

<br>

- **Eye-tracking 기반의 스마트홈 시스템 제안** 

[**주의**] 본 아이디어는 **<u>현재 최우선 순위로 고려하고 있는 아이디어</u>**이다.  
다만, 현실적으로 개발이 힘들 것으로 예상되는 부분이 있어, 확인해야 할 사항이 많다.
{: .notice--danger .text-center}

이 아이디어는 IoT 제품과 인터랙션이 가능한 **Eye-tracking** **스마트 글래스**를 개발함으로써 눈짓으로 제품들을 컨트롤 할 수 있는 스마트홈 시스템에 대한 제안이 핵심이다. 코어 아이디어는 **사람이 현재 어디를 보고있는지를 파악하는 것**이다. 스마트 글래스에는 **Outer Camera**/**Inner Camera**가 사용된다. **Outer Camera**를 사용하여 **현재 사람이 보고있는 정면을 이미지를 촬영**한다. **Inner Camera**로는 **사람의 눈 이미지를 촬영**한다.

Inner Camera를 사용하여 촬영된 동공을 통해 **현재 바라보고 있는 지점을 추정**하고, 이 결과를 바탕으로 Outer Camera에서 촬영한 이미지에서 **현재 어디를 보고있는 지를 파악**한다. 현재 학습된 데이터는 '**디스플레이를 바라보고 있는 사람**'에 대한 데이터이기 때문에 **<u>이를 실제로 적용할 수 있을 가능성은 낮을 것</u>**으로 보인다. 하지만 우리 팀은 이 아이디어가 굉장히 마음에 들어서 어느 정도 구현이 가능할지, 성능이 얼마나 나올지를 체크해보고자 한다.

한 가지 가능성으로 제시할 수 있는 사항은, **Outer Camera로 촬영한 이미지를 마치 스마트폰 화면처럼 영상처리를 해서 활용**하는 것이다. 이것이 어떻게 가능할지, 성능이 얼마나 나올지는 직접 확인해 보아야 한다.

> 그런데, Outer Camera로 촬영한 이미지를 스마트폰 화면처럼 영상처리를 한다면, 인식 범위에 제한이 생기게 될 것이다. 이는 어쩔 수 없이 생기는 한계일 것으로 생각된다. 논리적으로 가능성을 따져본 다음, 실제로 구현해보면서 원하는 동작을 끌어낼 수 있는지, 성능이 나오는지 등을 확인해 보자.

만약 이 기능을 구현할 수 있다면, 여러가지 IoT 제품 모형을 만들어서 동작을 시연할 수 있다. 예를 들어, **블라인드의 특정 지점을 3초 이상 바라본 상태에서 눈을 위 또는 아래로 옮기는 행위**를 한다면, **블라인드가 자동으로 올라가고 내려가는 식의 동작을 구현**할 수 있을 것이다. 또 다른 예시로는 **공기청정기 등의 전원 버튼을 3초 이상 바라볼 경우**, **전원 On/Off**를 가능하도록 만드는 기능도 구현할 수 있을 것이다.

이 때 중요한 사항은 **물체**(블라인드, 공기청정기 등)**를 인식해야 한다는 것**이다. 현재로서는 특정 지점에 Detection이 가능한 **Unique Image**를 붙여놓고, 사용자가 해당 지점을 바라보고 있을 때 그 특정 지점 근처 영역 내에 Unique Image가 Detection 될 경우 상호작용이 가능하도록 만드는 방식을 고려하고 있다.

<br>

그리고 이를 이용하면 다음 두 가지 상황을 만들어낼 수 있을 것이다.

1) **기존 제품에 Unique Image를 부착하여 센싱하고, 추가 H/W를 부착하여 동작 제어**  
   (*예를 들면 자동 블라인드를 올리고 내리는 버튼을 추가 H/W를 부착하여 조절하는 방식*)

   

2) **IoT 제품으로 동작하는 모형 제작**  
   (다만 이 방식도 현재로서는 Unique Image를 사용해야 할 것으로 생각됨.)

Unique Image를 사용하지 않고 **Object Detection**으로 물체를 구분하는 것이 맞지 않냐는 의견이 존재할 수도 있다. 하지만 **실제 스마트홈을 고려한다면 특정 장소에서 같은 물체가 여러 개 존재**할 수도 있기 때문에 Object를 **Unique하게 구별할 수 있는 방식의 Division Factor를 도입**하는 것이 맞다고 생각된다.

[**TODO**] 본 아이디어에 대해서 활용 가능한 추가적인 빅데이터가 인터넷에 존재하는지 확인해 볼 필요가 있으며,  
어떻게 테스트 구현을 진행할 것인지 철저하게 설계해야 한다.
{: .notice--success .text-center}

<br>

# 2. 추가 논의

## 김성웅 팀원 온라인 진행 방식 피드백

김성웅 팀원의 경우 학교까지 왕복 5시간이 걸리기 때문에 다른 팀원들보다 이동에 시간이 너무 많이 소요되었다. 그래서 이번에는 온라인 디스코드로 참여해 보았다. 다음 내용은 이에 대한 피드백이다.

- **김성웅 팀원의 목소리가 너무 작다.** => 김성웅 팀원의 마이크 변경, 입력 볼륨 높이기
- **아무래도 같이 있지 않다보니 자유롭게 말하기가 어렵다**. => 볼륨을 키워서 김성웅 팀원의 발언 시에 주의가 주목되도록 만들어 문제점 일부 해결, 모두 디스코드에 들어와 웹캠을 켜서 얼굴을 볼 수 있도록 해서 집중도를 향상할 수 있도록 하자.

<br>

## 추후 일정

<br>

- 2024-01-26 (금) 09:00에 오프라인 회의 진행 (인천대학교 송도 캠퍼스 이룸관)
- 현재 제시된 핵심 아이디어는 구현 난이도가 상당히 높다. 따라서 구현 난이도가 상대적으로 낮은 아이디어 1~2개 정도를 추가로 정한다.
- 이렇게 결정된 아이디어를 바탕으로 우선 순위를 설정, 역할을 분담한 후에 프로토타입을 구현하며 구현 가능성을 파악한다.

<br>

## 과제

- **TBA** (if needed).

<br>















